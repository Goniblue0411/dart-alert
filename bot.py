#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os, json, re, html, time
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Tuple
import requests

# =========================
# ENV
# =========================
DART_API_KEY = os.getenv("DART_API_KEY", "").strip()
TG_BOT_TOKEN = os.getenv("TG_BOT_TOKEN", "").strip()
TG_CHAT_ID   = os.getenv("TG_CHAT_ID", "").strip()

LOOKBACK_DAYS = int(os.getenv("LOOKBACK_DAYS", "3"))
PAGE_COUNT    = int(os.getenv("PAGE_COUNT", "100"))
MAX_PAGES     = int(os.getenv("MAX_PAGES", "30"))  # pagination cap
STATE_PATH    = os.getenv("STATE_PATH", "state.json")

# ì‹œì¥ í•„í„° (K=KOSPI, Q=KOSDAQ, N=KONEX) - list.json ìì²´ì— market êµ¬ë¶„ì´ ì§ì ‘ ì•ˆ ë‚˜ì˜¬ ìˆ˜ ìˆì–´ bodyì—ì„œ ì¶”ì¶œ
MARKET_CLASSES = [x.strip().upper() for x in os.getenv("MARKET_CLASSES", "K,Q,N").split(",") if x.strip()]

# ì¦ì/ë¬´ìƒ/ìœ ë¬´ìƒ ê´€ë ¨ ê³µì‹œëª… ë§¤ì¹­(ì œëª©)
INC_TITLE_RE = re.compile(r"(ìœ ìƒì¦ì|ë¬´ìƒì¦ì|ìœ ë¬´ìƒì¦ì)", re.I)

# "ì œ3ìë°°ì •"ì€ ë¬´ì¡°ê±´ ì œì™¸ (ì œëª©/ë³¸ë¬¸)
EXC_3RD_RE = re.compile(r"ì œ\s*3\s*ì\s*ë°°ì •", re.I)

# í¬í•¨ ì¡°ê±´(ë³¸ë¬¸): ì¼ë°˜ê³µëª¨/ì¼ë°˜ì£¼ì£¼/ì£¼ì£¼ë°°ì •/êµ¬ì£¼ì£¼/ê¸°ì¡´ì£¼ì£¼ ë“±
INC_BODY_RE = re.compile(r"(ì£¼ì£¼ë°°ì •|êµ¬ì£¼ì£¼|ê¸°ì¡´ì£¼ì£¼|ì¼ë°˜ê³µëª¨|ì¼ë°˜ì£¼ì£¼|ê³µëª¨)", re.I)

# DART API
LIST_URL = "https://opendart.fss.or.kr/api/list.json"
VIEW_URL = "https://dart.fss.or.kr/dsaf001/main.do?rcpNo={rcept_no}"
TG_SEND  = "https://api.telegram.org/bot{token}/sendMessage"

# Telegram limits: keep well under 4096
TG_MAX = 3500

UA = {"User-Agent": "dart-alert-actions/2.0"}

# =========================
# Utils
# =========================
def must_env():
    missing = []
    if not DART_API_KEY: missing.append("DART_API_KEY")
    if not TG_BOT_TOKEN: missing.append("TG_BOT_TOKEN")
    if not TG_CHAT_ID:   missing.append("TG_CHAT_ID")
    if missing:
        raise SystemExit(f"[ERROR] Missing env: {', '.join(missing)}")

def load_state() -> Dict[str, Any]:
    try:
        with open(STATE_PATH, "r", encoding="utf-8") as f:
            st = json.load(f)
        if not isinstance(st, dict): raise ValueError("state not dict")
        st.setdefault("seen", [])
        st.setdefault("seen_set", {})  # optional cache
        return st
    except Exception:
        return {"seen": [], "seen_set": {}}

def save_state(st: Dict[str, Any]) -> None:
    # keep only last N seen to avoid repo bloat
    seen = st.get("seen", [])
    if len(seen) > 4000:
        st["seen"] = seen[-4000:]
    with open(STATE_PATH, "w", encoding="utf-8") as f:
        json.dump({"seen": st.get("seen", [])}, f, ensure_ascii=False, indent=2)

def is_seen(st: Dict[str, Any], rcept_no: str) -> bool:
    # use list for persistence; build set on the fly for speed
    seen_list = st.get("seen", [])
    if "seen_set" not in st or not st["seen_set"]:
        st["seen_set"] = {x: True for x in seen_list}
    return bool(st["seen_set"].get(rcept_no))

def mark_seen(st: Dict[str, Any], rcept_no: str) -> None:
    if is_seen(st, rcept_no): 
        return
    st["seen"].append(rcept_no)
    st["seen_set"][rcept_no] = True

def tg_send_html(text: str, button_url: Optional[str] = None) -> None:
    url = TG_SEND.format(token=TG_BOT_TOKEN)
    payload = {
        "chat_id": TG_CHAT_ID,
        "text": text,
        "parse_mode": "HTML",
        "disable_web_page_preview": True
    }
    if button_url:
        # inline keyboard
        payload["reply_markup"] = json.dumps({
            "inline_keyboard": [[{"text": "ğŸ“„ DART ì—´ê¸°", "url": button_url}]]
        }, ensure_ascii=False)
    r = requests.post(url, data=payload, timeout=25)
    r.raise_for_status()

def clamp_text(s: str, n: int = TG_MAX) -> str:
    if len(s) <= n:
        return s
    return s[: n-30] + "\nâ€¦(ê¸¸ì´ ì œí•œìœ¼ë¡œ ì¼ë¶€ ìƒëµ)â€¦"

def norm_space(s: str) -> str:
    return re.sub(r"\s+", " ", (s or "")).strip()

def clean_value(v: str) -> str:
    if not v:
        return ""
    t = norm_space(v)
    if t in ("-", "N/A", "n/a", "NA", "na"):
        return ""
    return t

def add_line(lines: List[str], k: str, v: str) -> None:
    v2 = clean_value(v)
    if not v2:
        return
    lines.append(f"â€¢ <b>{html.escape(k)}</b>: {html.escape(v2)}")

def money_to_int(s: str) -> int:
    if not s:
        return 0
    t = re.sub(r"[^\d]", "", s)
    try:
        return int(t) if t else 0
    except Exception:
        return 0

def fmt_krw(n: int) -> str:
    if n <= 0:
        return ""
    return f"{n:,}ì›"

# =========================
# DART fetch (pagination)
# =========================
def fetch_disclosures() -> List[Dict[str, Any]]:
    end_de = datetime.now().strftime("%Y%m%d")
    bgn_de = (datetime.now() - timedelta(days=LOOKBACK_DAYS)).strftime("%Y%m%d")

    all_items: List[Dict[str, Any]] = []

    page_no = 1
    while page_no <= MAX_PAGES:
        params = {
            "crtfc_key": DART_API_KEY,
            "bgn_de": bgn_de,
            "end_de": end_de,
            "pblntf_ty": "B",        # ì£¼ìš”ì‚¬í•­ë³´ê³ ì„œ ìœ„ì£¼
            "page_no": page_no,
            "page_count": PAGE_COUNT,
            "sort": "date",
            "sort_mth": "desc",
        }
        r = requests.get(LIST_URL, params=params, headers=UA, timeout=25)
        r.raise_for_status()
        data = r.json()

        status = data.get("status")
        if status == "013":
            break
        if status != "000":
            raise RuntimeError(f"DART list error: {status} / {data.get('message')}")

        items = data.get("list", []) or []
        if not items:
            break

        all_items.extend(items)

        # if less than page_count, it's last page
        if len(items) < PAGE_COUNT:
            break
        page_no += 1

    return all_items

# =========================
# Report HTML fetch + field extraction
# =========================
def fetch_report_html(rcept_no: str) -> str:
    """Best-effort: fetch main viewer HTML text. It contains some searchable text and labels."""
    url = VIEW_URL.format(rcept_no=rcept_no)
    r = requests.get(url, headers=UA, timeout=25)
    r.raise_for_status()
    return r.text

def extract_field(body_html: str, label: str) -> str:
    """
    ë§¤ìš° ëŸ¬í”„í•œ ë¼ë²¨ ì¶”ì¶œ:
    - ëª¨ë°”ì¼/ì›¹ì—ì„œ í‘œ/ë¼ë²¨ì´ HTMLë¡œ ì„ì—¬ ë“¤ì–´ì˜¤ë¯€ë¡œ 'label ... ê°’' í˜•íƒœë¥¼ ì •ê·œì‹ìœ¼ë¡œ ì¡ìŒ
    - ì‹¤íŒ¨í•˜ë©´ ë¹ˆê°’ -> ìë™ ìˆ¨ê¹€
    """
    if not body_html:
        return ""
    text = html.unescape(body_html)
    # íƒœê·¸ ì œê±°(ê°„ë‹¨)
    text = re.sub(r"<[^>]+>", " ", text)
    text = re.sub(r"\s+", " ", text)

    # label ë’¤ì— ê°’ì´ ë”°ë¼ì˜¤ëŠ” íŒ¨í„´(ìµœëŒ€ 80ì)
    # ì˜ˆ: "ìê¸ˆì¡°ë‹¬ì˜ ëª©ì  ê¸°íƒ€ìê¸ˆ(ì›) 3,138,000,000"
    pat = re.compile(rf"{re.escape(label)}\s*[:ï¼š]?\s*([^\n\r]{{1,80}})", re.I)
    m = pat.search(text)
    if not m:
        return ""
    val = m.group(1)
    # ë‹¤ìŒ ë¼ë²¨/í‘œ í—¤ë”ë¡œ ì´ì–´ì§€ëŠ” í”í•œ ì¡ìŒ ì»·
    val = re.split(r"(ë³´í†µì£¼ì‹|ê¸°íƒ€ì£¼ì‹|ì›\)|ì£¼\)|ì˜ˆì •|í™•ì •|ê¸°ì¤€ì¼|ìƒì¥|ì²­ì•½|ê¸°ê°„)", val)[0]
    return val.strip()

def extract_market_hint(body_html: str) -> str:
    """
    KOSPI/KOSDAQ/KONEX íŒíŠ¸ ì¶”ì¶œ(ì—†ìœ¼ë©´ ë¹ˆê°’).
    """
    if not body_html:
        return ""
    t = body_html
    if re.search(r"KOSDAQ", t, re.I): return "KOSDAQ"
    if re.search(r"KOSPI", t, re.I):  return "KOSPI"
    if re.search(r"KONEX", t, re.I):  return "KONEX"
    return ""

def should_include(rpt_nm: str, body_html: str) -> bool:
    # 1) ì œëª©ì— ì¦ì/ë¬´ìƒ/ìœ ë¬´ìƒ í¬í•¨ í•„ìˆ˜
    if not rpt_nm or not INC_TITLE_RE.search(rpt_nm):
        return False

    # 2) ì œ3ìë°°ì •ì€ ë¬´ì¡°ê±´ ì œì™¸(ì œëª©/ë³¸ë¬¸)
    if EXC_3RD_RE.search(rpt_nm or ""):
        return False
    if body_html and EXC_3RD_RE.search(body_html):
        return False

    # 3) ë³¸ë¬¸ì— "ì£¼ì£¼/ì¼ë°˜" íŒíŠ¸ê°€ ìˆì–´ì•¼ í¬í•¨
    # (ì´ ì¡°ê±´ ë•Œë¬¸ì— "ìœ ìƒì¦ìê²°ì •"ì¸ë° ë°°ì •ë°©ì‹ í‘œê¸°ê°€ ì—†ëŠ” ì¼€ì´ìŠ¤ê°€ ë¹ ì§ˆ ìˆ˜ ìˆìŒ.
    #  ê·¸ëŸ° ì¼€ì´ìŠ¤ë¥¼ í¬í•¨í•˜ê³  ì‹¶ìœ¼ë©´ ì´ ì¡°ê±´ì„ ì™„í™”í•´ì¤„ ìˆ˜ ìˆìŒ.)
    if not (body_html and INC_BODY_RE.search(body_html)):
        return False

    return True

# =========================
# Risk score (simple, disclosure-based)
# =========================
def compute_risk_score(raise_amt_krw: int, discount_pct: Optional[float] = None, mc_ratio: Optional[float] = None) -> Tuple[int, str]:
    """
    0~100 ìŠ¤ì½”ì–´(ê°„ë‹¨í˜•)
    - ì¡°ë‹¬ê¸ˆì•¡(ì›) í¬ë©´ ì ìˆ˜â†‘
    - í• ì¸ìœ¨(%) í¬ë©´ ì ìˆ˜â†‘ (ì˜µì…˜)
    - ì‹œì´ëŒ€ë¹„(%) í¬ë©´ ì ìˆ˜â†‘ (ì˜µì…˜)
    """
    score = 0

    # raise amount bucket
    if raise_amt_krw >= 300_000_000_000: score += 50
    elif raise_amt_krw >= 100_000_000_000: score += 40
    elif raise_amt_krw >= 30_000_000_000:  score += 30
    elif raise_amt_krw >= 10_000_000_000:  score += 20
    elif raise_amt_krw >= 3_000_000_000:   score += 12
    elif raise_amt_krw >= 1_000_000_000:   score += 8
    elif raise_amt_krw > 0:                score += 5

    if discount_pct is not None:
        if discount_pct >= 30: score += 25
        elif discount_pct >= 20: score += 18
        elif discount_pct >= 10: score += 10
        elif discount_pct > 0: score += 5

    if mc_ratio is not None:
        # mc_ratio in percent
        if mc_ratio >= 50: score += 25
        elif mc_ratio >= 30: score += 18
        elif mc_ratio >= 15: score += 12
        elif mc_ratio >= 5: score += 6

    score = max(0, min(100, score))

    if score >= 70: label = "ğŸ”´ ë†’ìŒ"
    elif score >= 40: label = "ğŸŸ  ë³´í†µ"
    else: label = "ğŸŸ¢ ë‚®ìŒ"
    return score, label

# =========================
# Grouping + Message
# =========================
def build_card(company: str, market: str, rcept_dt: str, rpt_nm: str, rcept_no: str, body_html: str) -> Tuple[str, str]:
    url = VIEW_URL.format(rcept_no=rcept_no)

    lines: List[str] = []
    lines.append(f"ğŸ“Œ <b>ì¦ì ê³µì‹œ ê°ì§€</b>")
    lines.append(f"â€¢ <b>íšŒì‚¬</b>: {html.escape(company)}" + (f" ({html.escape(market)})" if market else ""))
    lines.append(f"â€¢ <b>ì ‘ìˆ˜ì¼</b>: {html.escape(rcept_dt)}")
    lines.append("")  # blank

    # headline
    lines.append(f"<b>ê³µì‹œ</b>")
    lines.append(f"â€“ {html.escape(rpt_nm)}")
    lines.append(f"(<code>{html.escape(rcept_no)}</code>)")

    # Details (N/A auto-hide)
    d: List[str] = []
    # ìš”ì²­ í•„ë“œë“¤
    add_line(d, "ìê¸ˆì¡°ë‹¬ì˜ ëª©ì ", extract_field(body_html, "ìê¸ˆì¡°ë‹¬ì˜ ëª©ì "))
    add_line(d, "ì‹ ì£¼ë°°ì •ê¸°ì¤€ì¼", extract_field(body_html, "ì‹ ì£¼ë°°ì •ê¸°ì¤€ì¼"))
    add_line(d, "ì˜ˆì •ê°€", extract_field(body_html, "ì˜ˆì •ë°œí–‰ê°€ì•¡") or extract_field(body_html, "ì˜ˆì •ê°€ì•¡") or extract_field(body_html, "ì˜ˆì •ê°€"))
    add_line(d, "í™•ì •ì¼", extract_field(body_html, "í™•ì •ë°œí–‰ê°€ì•¡") or extract_field(body_html, "í™•ì •ì¼"))
    add_line(d, "ì‹ ì£¼ì¸ìˆ˜ê¶Œìƒì¥ì˜ˆì •ê¸°ê°„", extract_field(body_html, "ì‹ ì£¼ì¸ìˆ˜ê¶Œì¦ì„œ ìƒì¥ì˜ˆì •ê¸°ê°„") or extract_field(body_html, "ì‹ ì£¼ì¸ìˆ˜ê¶Œìƒì¥ì˜ˆì •ê¸°ê°„"))
    add_line(d, "ì²­ì•½ì¼", extract_field(body_html, "ì²­ì•½ì¼") or extract_field(body_html, "ì²­ì•½ê¸°ê°„"))
    add_line(d, "ì‹ ì£¼ì˜ìƒì¥ì˜ˆì •ì¼", extract_field(body_html, "ì‹ ì£¼ì˜ ìƒì¥ì˜ˆì •ì¼") or extract_field(body_html, "ì‹ ì£¼ ìƒì¥ì˜ˆì •ì¼") or extract_field(body_html, "ìƒì¥ì˜ˆì •ì¼"))

    # ì¡°ë‹¬ê¸ˆì•¡(ì›) ì¶”ì • (ë³¸ë¬¸ì—ì„œ "ê¸°íƒ€ìê¸ˆ(ì›)" ê°™ì€ í•­ëª©ì´ ì¡íˆë©´ ìˆ«ì ì¸ì‹)
    # ì—¬ëŸ¬ ì¹¸ì´ ìˆì„ ìˆ˜ ìˆì–´ ê°€ì¥ í° ìˆ«ì í•˜ë‚˜ë¥¼ ì¡°ë‹¬ê¸ˆì•¡ìœ¼ë¡œ ì‚¬ìš©(ê°„ë‹¨í˜•)
    raise_candidates = re.findall(r"(\d{1,3}(?:,\d{3})+)\s*ì›", html.unescape(re.sub(r"<[^>]+>", " ", body_html or "")))
    raise_amt = 0
    for c in raise_candidates:
        raise_amt = max(raise_amt, money_to_int(c))
    if raise_amt > 0:
        add_line(d, "ì¡°ë‹¬ê¸ˆì•¡(ì¶”ì •)", fmt_krw(raise_amt))

    # Risk (simple)
    score, label = compute_risk_score(raise_amt if raise_amt else 0)
    d.append(f"â€¢ <b>ìœ„í—˜ë„</b>: {label} (<b>{score}</b>/100)")

    if d:
        lines.append("")
        lines.append("<b>ìš”ì•½</b>")
        lines.extend(d)

    text = clamp_text("\n".join(lines))
    return text, url

def group_items(items: List[Dict[str, Any]]) -> Dict[str, List[Dict[str, Any]]]:
    """
    ê°™ì€ íšŒì‚¬(corp_name) ê¸°ì¤€ ë¬¶ê¸°.
    """
    grouped: Dict[str, List[Dict[str, Any]]] = {}
    for it in items:
        corp = (it.get("corp_name") or "N/A").strip()
        grouped.setdefault(corp, []).append(it)
    return grouped

# =========================
# Main
# =========================
def main():
    must_env()
    st = load_state()

    items = fetch_disclosures()

    # ìµœì‹ ìˆœìœ¼ë¡œ ì˜¤ì§€ë§Œ, ë°œì†¡ì€ ì˜¤ë˜ëœ ê²ƒë¶€í„°(ì—­ìˆœ)
    items = list(reversed(items))

    send_count = 0
    candidate: List[Dict[str, Any]] = []

    # 1) ìˆ˜ì§‘ + í•„í„°ë§
    for it in items:
        rpt_nm = (it.get("report_nm") or "").strip()
        if not rpt_nm:
            continue
        if not INC_TITLE_RE.search(rpt_nm):
            continue

        rcept_no = (it.get("rcept_no") or "").strip()
        if not rcept_no:
            continue
        if is_seen(st, rcept_no):
            continue

        # HTML fetch (best-effort)
        body_html = ""
        try:
            body_html = fetch_report_html(rcept_no)
        except Exception:
            body_html = ""

        # include/exclude íŒë‹¨
        if not should_include(rpt_nm, body_html):
            # ì œì™¸ ì²˜ë¦¬ë„ seenìœ¼ë¡œ ì°ì–´ë‘ë©´ ê°™ì€ ê³µì‹œë¡œ ê³„ì† ì¬ì‹œë„ ì•ˆ í•¨
            mark_seen(st, rcept_no)
            continue

        # ì‹œì¥ íŒíŠ¸
        market = extract_market_hint(body_html)
        if market:
            # MARKET_CLASSES í•„í„°
            if market == "KOSPI" and "K" not in MARKET_CLASSES: 
                mark_seen(st, rcept_no); continue
            if market == "KOSDAQ" and "Q" not in MARKET_CLASSES:
                mark_seen(st, rcept_no); continue
            if market == "KONEX" and "N" not in MARKET_CLASSES:
                mark_seen(st, rcept_no); continue

        it["_body_html"] = body_html
        it["_market"] = market
        candidate.append(it)

    if not candidate:
        print(f"OK sent=0 seen={len(st.get('seen', []))}")
        save_state(st)
        return

    # 2) íšŒì‚¬ë³„ ë¬¶ê¸°
    grouped = group_items(candidate)

    # 3) ë°œì†¡(íšŒì‚¬ë‹¹ 1ê±´ ë©”ì‹œì§€ë¡œ ë¬¶ì–´ì„œ)
    for corp, its in grouped.items():
        # ìµœì‹  10ê°œê¹Œì§€ë§Œ í‘œì‹œ
        its = its[-10:]

        # ì¹´ë“œ 1ì¥ + í•˜ë‹¨ì— ê³µì‹œ ë¦¬ìŠ¤íŠ¸(ì—¬ëŸ¬ ê±´)
        first = its[0]
        rcept_dt = (first.get("rcept_dt") or "").strip()
        rpt_nm   = (first.get("report_nm") or "").strip()
        rcept_no = (first.get("rcept_no") or "").strip()
        market   = first.get("_market", "")

        card_text, card_url = build_card(
            company=corp,
            market=market,
            rcept_dt=rcept_dt,
            rpt_nm=rpt_nm,
            rcept_no=rcept_no,
            body_html=first.get("_body_html", "")
        )

        # ì—¬ëŸ¬ ê³µì‹œê°€ ìˆìœ¼ë©´ ë¦¬ìŠ¤íŠ¸ ì¶”ê°€
        if len(its) > 1:
            extra_lines = ["", "<b>ê°™ì€ íšŒì‚¬ ì¶”ê°€ ê³µì‹œ</b>"]
            for x in its[1:]:
                extra_lines.append(f"â€¢ {html.escape((x.get('rcept_dt') or '').strip())} â€“ {html.escape((x.get('report_nm') or '').strip())} (<code>{html.escape((x.get('rcept_no') or '').strip())}</code>)")
            card_text = clamp_text(card_text + "\n" + "\n".join(extra_lines))

        tg_send_html(card_text, button_url=card_url)
        send_count += 1

        # seen ì²˜ë¦¬
        for x in its:
            mark_seen(st, (x.get("rcept_no") or "").strip())

    save_state(st)
    print(f"OK sent={send_count} seen={len(st.get('seen', []))}")

if __name__ == "__main__":
    main()
