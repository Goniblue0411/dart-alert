#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os, json, re, io, zipfile, html
import requests
from datetime import datetime, timedelta

# =========================
# Secrets (GitHub repo Secrets)
# =========================
DART_API_KEY = os.environ["DART_API_KEY"].strip()
TG_BOT_TOKEN = os.environ["TG_BOT_TOKEN"].strip()
TG_CHAT_ID   = os.environ["TG_CHAT_ID"].strip()

# =========================
# Config
# =========================
LOOKBACK_DAYS = int(os.getenv("LOOKBACK_DAYS", "3"))

# ì‹œì¥ í•„í„° (ë¹ˆ ê°’ì´ë©´ ì „ì²´)
# Y=KOSPI, K=KOSDAQ, N=KONEX, E=OTHER
MARKET_CLASSES = [x.strip().upper() for x in os.getenv("MARKET_CLASSES", "Y,K,N").split(",") if x.strip()]

# í˜ì´ì§€ë„¤ì´ì…˜
MAX_PAGES  = int(os.getenv("MAX_PAGES", "12"))
PAGE_COUNT = int(os.getenv("PAGE_COUNT", "100"))

STATE_PATH = "state.json"
SEEN_MAX   = 8000

# ë„¤ì´ë²„ ê¸ˆìœµ ì¡°íšŒ íƒ€ì„ì•„ì›ƒ/ì¬ì‹œë„
NAVER_TIMEOUT = int(os.getenv("NAVER_TIMEOUT", "20"))
NAVER_RETRY   = int(os.getenv("NAVER_RETRY", "2"))

# =========================
# Filters (ì •ì±…)
# =========================
# 1) ë³´ê³ ì„œëª…: ìœ ìƒ/ë¬´ìƒ/ìœ ë¬´ìƒ "ê²°ì •"ë§Œ ëŒ€ìƒìœ¼ë¡œ
INC_REPORT = re.compile(
    r"(ìœ ìƒì¦ì\s*ê²°ì •|ìœ ìƒì¦ìê²°ì •|ë¬´ìƒì¦ì\s*ê²°ì •|ë¬´ìƒì¦ìê²°ì •|ìœ ë¬´ìƒì¦ì\s*ê²°ì •|ìœ ë¬´ìƒì¦ìê²°ì •)",
    re.I
)

# 2) ì›ë¬¸ì—ì„œ ì œ3ìë°°ì •ì€ ë¬´ì¡°ê±´ ì œì™¸
EXC_3RD = re.compile(r"(ì œ\s*3\s*ì\s*ë°°ì •|ì œ3ìë°°ì •)", re.I)

# 3) ì›ë¬¸ì—ì„œ í—ˆìš©ë˜ëŠ” ë°°ì • ë°©ì‹
ALLOW_GENERAL = re.compile(r"(ì¼ë°˜\s*ì£¼ì£¼\s*ë°°ì •|ì¼ë°˜ì£¼ì£¼ë°°ì •)", re.I)
ALLOW_SHAREHOLDER = re.compile(r"(ì£¼ì£¼\s*ë°°ì •|ì£¼ì£¼ë°°ì •|êµ¬ì£¼ì£¼\s*ì²­ì•½|êµ¬ì£¼ì£¼ì²­ì•½|êµ¬ì£¼ì£¼)", re.I)

# =========================
# URLs
# =========================
LIST_URL = "https://opendart.fss.or.kr/api/list.json"
DOC_URL  = "https://opendart.fss.or.kr/api/document.xml"
VIEW_URL = "https://dart.fss.or.kr/dsaf001/main.do?rcpNo={}"
TG_SEND  = "https://api.telegram.org/bot{}/sendMessage"

NAVER_ITEM = "https://finance.naver.com/item/main.nhn?code={}"

S = requests.Session()
S.headers.update({"User-Agent": "dart-alert-github-actions/6.0"})

TG_MAX = 4096

# =========================
# state.json
# =========================
def load_state():
    try:
        with open(STATE_PATH, "r", encoding="utf-8") as f:
            st = json.load(f)
        if not isinstance(st, dict):
            return {"seen": []}
        if "seen" not in st or not isinstance(st["seen"], list):
            st["seen"] = []
        return st
    except Exception:
        return {"seen": []}

def save_state(st):
    seen = st.get("seen", [])
    if not isinstance(seen, list):
        seen = []
    st["seen"] = seen[-SEEN_MAX:]
    with open(STATE_PATH, "w", encoding="utf-8") as f:
        json.dump(st, f, ensure_ascii=False, indent=2)

def is_seen(st, rcept_no: str) -> bool:
    return rcept_no in set(st.get("seen", []))

def mark_seen(st, rcept_no: str):
    st.setdefault("seen", []).append(rcept_no)

# =========================
# Telegram
# =========================
def tg_send(text: str, button_url: str | None = None):
    payload = {
        "chat_id": TG_CHAT_ID,
        "text": text,
        "parse_mode": "HTML",
        "disable_web_page_preview": True,
    }
    if button_url:
        payload["reply_markup"] = json.dumps(
            {"inline_keyboard": [[{"text": "ğŸ“„ DART ì—´ê¸°", "url": button_url}]]},
            ensure_ascii=False
        )
    r = S.post(TG_SEND.format(TG_BOT_TOKEN), data=payload, timeout=30)
    r.raise_for_status()

def tg_send_safe(text: str, button_url: str | None = None):
    if len(text) <= TG_MAX:
        tg_send(text, button_url)
        return
    tg_send(text[: TG_MAX - 40] + "\n\n(â€¦ì¤‘ëµ)", button_url)

# =========================
# DART list.json (pagination)
# =========================
def market_ok(corp_cls: str) -> bool:
    corp_cls = (corp_cls or "").strip().upper()
    if not MARKET_CLASSES:
        return True
    return corp_cls in MARKET_CLASSES

def fetch_list_pages():
    end_de = datetime.now().strftime("%Y%m%d")
    bgn_de = (datetime.now() - timedelta(days=LOOKBACK_DAYS)).strftime("%Y%m%d")

    out = []
    for p in range(1, MAX_PAGES + 1):
        j = S.get(
            LIST_URL,
            params=dict(
                crtfc_key=DART_API_KEY,
                bgn_de=bgn_de,
                end_de=end_de,
                pblntf_ty="B",
                page_no=p,
                page_count=PAGE_COUNT,
                sort="date",
                sort_mth="desc",
            ),
            timeout=30,
        ).json()

        status = j.get("status")
        if status == "013":
            break
        if status != "000":
            raise RuntimeError(f"LIST error {status}: {j.get('message')}")

        lst = j.get("list") or []
        if not lst:
            break
        out.extend(lst)

        # total_count ê¸°ë°˜ ì¢…ë£Œ(ìˆì„ ë•Œë§Œ)
        try:
            total = int(j.get("total_count") or 0)
            pc    = int(j.get("page_count") or PAGE_COUNT)
            if total and total <= p * pc:
                break
        except Exception:
            pass

    # rcept_no ì¤‘ë³µ ì œê±°
    seen = set()
    dedup = []
    for it in out:
        rno = (it.get("rcept_no") or "").strip()
        if not rno or rno in seen:
            continue
        seen.add(rno)
        dedup.append(it)

    # ì˜¤ë˜ëœ ê²ƒë¶€í„° ì²˜ë¦¬
    dedup.sort(key=lambda x: (x.get("rcept_dt", ""), x.get("rcept_no", "")))
    return dedup

# =========================
# document.xml fetch + textify
# =========================
def _xml_to_text(xml_bytes: bytes) -> str:
    s = xml_bytes.decode("utf-8", errors="ignore")
    s = re.sub(r"(?i)<br\s*/?>", "\n", s)
    s = re.sub(r"(?i)</(tr|p|div|li|h\d)>", "\n", s)
    s = re.sub(r"<[^>]+>", " ", s)
    s = html.unescape(s)
    s = re.sub(r"[ \t\r\f\v]+", " ", s)
    s = re.sub(r"\n\s+", "\n", s)
    s = re.sub(r"\n{3,}", "\n\n", s)
    return s.strip()

def fetch_document_text(rcept_no: str) -> str:
    r = S.get(DOC_URL, params={"crtfc_key": DART_API_KEY, "rcept_no": rcept_no}, timeout=60)
    r.raise_for_status()
    raw = r.content

    texts = []
    is_zip = (r.headers.get("Content-Type", "").lower().find("zip") >= 0) or (raw[:2] == b"PK")
    if is_zip:
        with zipfile.ZipFile(io.BytesIO(raw)) as z:
            for name in z.namelist():
                if name.lower().endswith((".xml", ".html", ".htm")):
                    try:
                        texts.append(_xml_to_text(z.read(name)))
                    except Exception:
                        pass
    else:
        texts.append(_xml_to_text(raw))

    return "\n\n".join([t for t in texts if t])

# =========================
# classify allocation + type
# =========================
def classify_event_type(report_nm: str) -> str:
    rn = report_nm or ""
    if re.search(r"ë¬´ìƒì¦ì", rn):
        return "ë¬´ìƒ"
    if re.search(r"ìœ ë¬´ìƒì¦ì", rn):
        return "ìœ ë¬´ìƒ"
    if re.search(r"ìœ ìƒì¦ì", rn):
        return "ìœ ìƒ"
    return "N/A"

def classify_allocation(doc_text: str) -> str:
    if ALLOW_GENERAL.search(doc_text):
        return "ì¼ë°˜ì£¼ì£¼ë°°ì •"
    if ALLOW_SHAREHOLDER.search(doc_text):
        return "ì£¼ì£¼ë°°ì •"
    return "N/A"

# =========================
# Field extraction
# =========================
def _norm_ws(s: str) -> str:
    return re.sub(r"\s{2,}", " ", (s or "")).strip()

def pick_first_by_labels(text: str, labels: list[str], maxlen: int = 140) -> str:
    if not text:
        return "N/A"
    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]
    for i, ln in enumerate(lines):
        for lb in labels:
            if lb in ln:
                after = ln.split(lb, 1)[1]
                after = re.sub(r"^[\s:\-Â·â€¢\)]+", "", after).strip()
                after = _norm_ws(after)

                if len(after) < 2 and i + 1 < len(lines):
                    nxt = _norm_ws(lines[i + 1])
                    if nxt and not any(x in nxt for x in labels):
                        after = _norm_ws((after + " " + nxt).strip())

                if after:
                    return after[:maxlen].strip()
    return "N/A"

def pick_multi_by_labels(text: str, labels: list[str], max_items: int = 6, maxlen_each: int = 90) -> str:
    if not text:
        return "N/A"
    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]
    hits = []
    for i, ln in enumerate(lines):
        for lb in labels:
            if lb in ln:
                after = ln.split(lb, 1)[1]
                after = re.sub(r"^[\s:\-Â·â€¢\)]+", "", after).strip()
                after = _norm_ws(after)
                if len(after) < 2 and i + 1 < len(lines):
                    nxt = _norm_ws(lines[i + 1])
                    if nxt and lb not in nxt:
                        after = _norm_ws((after + " " + nxt).strip())
                if after:
                    hits.append(f"{lb}: {after[:maxlen_each].strip()}")

    uniq, seen = [], set()
    for h in hits:
        key = re.sub(r"\s+", " ", h)
        if key in seen:
            continue
        seen.add(key)
        uniq.append(h)
        if len(uniq) >= max_items:
            break

    if not uniq:
        return "N/A"
    out = " / ".join(uniq)
    return out[:420] + ("â€¦" if len(out) > 420 else "")

def extract_money_purpose(text: str) -> str:
    v = pick_first_by_labels(text, [
        "ìê¸ˆì¡°ë‹¬ì˜ ëª©ì ", "ìê¸ˆì¡°ë‹¬ ëª©ì ", "ìê¸ˆì¡°ë‹¬ì˜ëª©ì ",
        "ìê¸ˆì˜ ì‚¬ìš©ëª©ì ", "ìê¸ˆì‚¬ìš©ëª©ì ", "ìê¸ˆ ì‚¬ìš© ëª©ì ",
        "ì¡°ë‹¬ìê¸ˆì˜ ì‚¬ìš©ëª©ì ", "ì¡°ë‹¬ ìê¸ˆì˜ ì‚¬ìš©ëª©ì ",
    ], maxlen=220)
    if v != "N/A":
        return v

    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]
    keys = ["ì‹œì„¤", "ìš´ì˜", "ì±„ë¬´", "íƒ€ë²•ì¸", "ê¸°íƒ€", "ì—°êµ¬", "M&A", "ì¸ìˆ˜", "íˆ¬ì"]
    amt_pat = re.compile(r"(\d{1,3}(?:,\d{3})+|\d+)\s*ì›")
    hits = []
    for ln in lines:
        if any(k in ln for k in keys) and amt_pat.search(ln):
            hits.append(_norm_ws(ln))
        if len(hits) >= 4:
            break
    if hits:
        out = " / ".join(hits)
        return out[:240] + ("â€¦" if len(out) > 240 else "")
    return "N/A"

def extract_fields(doc_text: str) -> dict:
    fields = {}
    fields["ìê¸ˆì¡°ë‹¬ì˜ëª©ì "] = extract_money_purpose(doc_text)

    fields["ì‹ ì£¼ë°°ì •ê¸°ì¤€ì¼"] = pick_first_by_labels(doc_text, [
        "ì‹ ì£¼ë°°ì •ê¸°ì¤€ì¼", "ì‹ ì£¼ ë°°ì • ê¸°ì¤€ì¼", "ë°°ì •ê¸°ì¤€ì¼", "ë°°ì • ê¸°ì¤€ì¼",
        "ì‹ ì£¼ë°°ì • ê¸°ì¤€ì¼", "ê¶Œë¦¬ë½ ê¸°ì¤€ì¼",
    ])

    fields["ì˜ˆì •ê°€"] = pick_first_by_labels(doc_text, [
        "ì˜ˆì •ë°œí–‰ê°€ì•¡", "ì˜ˆì • ë°œí–‰ê°€ì•¡", "ë°œí–‰ê°€ì•¡(ì˜ˆì •)", "ë°œí–‰ê°€ì•¡ (ì˜ˆì •)",
        "ì˜ˆì •ë°œí–‰ê°€", "ì˜ˆì • ë°œí–‰ê°€", "ì˜ˆì •ê°€", "ì˜ˆì •ê°€ì•¡",
        "1ì£¼ë‹¹ ë°œí–‰ê°€ì•¡(ì˜ˆì •)", "1ì£¼ë‹¹ ë°œí–‰ê°€ì•¡ (ì˜ˆì •)",
    ], maxlen=160)

    fields["í™•ì •ì¼"] = pick_first_by_labels(doc_text, [
        "ë°œí–‰ê°€ì•¡í™•ì •ì¼", "ë°œí–‰ê°€ì•¡ í™•ì •ì¼",
        "í™•ì •ì¼", "ê°€ê²©í™•ì •ì¼", "ê°€ê²© í™•ì •ì¼",
        "ë°œí–‰ê°€ í™•ì •ì¼", "ë°œí–‰ê°€ì•¡ì˜ í™•ì •ì¼",
    ])

    fields["ì‹ ì£¼ì¸ìˆ˜ê¶Œìƒì¥ì˜ˆì •ê¸°ê°„"] = pick_first_by_labels(doc_text, [
        "ì‹ ì£¼ì¸ìˆ˜ê¶Œì¦ì„œ ìƒì¥ì˜ˆì •ê¸°ê°„", "ì‹ ì£¼ì¸ìˆ˜ê¶Œì¦ì„œìƒì¥ì˜ˆì •ê¸°ê°„",
        "ì‹ ì£¼ì¸ìˆ˜ê¶Œ ìƒì¥ì˜ˆì •ê¸°ê°„", "ì‹ ì£¼ì¸ìˆ˜ê¶Œìƒì¥ì˜ˆì •ê¸°ê°„",
        "ì‹ ì£¼ì¸ìˆ˜ê¶Œì¦ì„œ ìƒì¥ê¸°ê°„", "ì‹ ì£¼ì¸ìˆ˜ê¶Œì¦ì„œìƒì¥ê¸°ê°„",
        "ì‹ ì£¼ì¸ìˆ˜ê¶Œ ìƒì¥ê¸°ê°„", "ì‹ ì£¼ì¸ìˆ˜ê¶Œìƒì¥ê¸°ê°„",
    ], maxlen=200)

    fields["ì²­ì•½ì¼"] = pick_multi_by_labels(doc_text, [
        "ìš°ë¦¬ì‚¬ì£¼ì¡°í•© ì²­ì•½ì¼", "ìš°ë¦¬ì‚¬ì£¼ì¡°í•©ì²­ì•½ì¼",
        "êµ¬ì£¼ì£¼ ì²­ì•½ì¼", "êµ¬ì£¼ì£¼ì²­ì•½ì¼",
        "ì¼ë°˜ê³µëª¨ ì²­ì•½ì¼", "ì¼ë°˜ê³µëª¨ì²­ì•½ì¼",
        "ì¼ë°˜ì²­ì•½ì¼",
        "ì²­ì•½ì¼",
    ])

    fields["ì‹ ì£¼ì˜ìƒì¥ì˜ˆì •ì¼"] = pick_first_by_labels(doc_text, [
        "ì‹ ì£¼ì˜ ìƒì¥ì˜ˆì •ì¼", "ì‹ ì£¼ì˜ìƒì¥ì˜ˆì •ì¼",
        "ì‹ ì£¼ ìƒì¥ì˜ˆì •ì¼", "ì‹ ì£¼ìƒì¥ì˜ˆì •ì¼",
        "ì‹ ì£¼ê¶Œ ìƒì¥ì˜ˆì •ì¼", "ì‹ ì£¼ê¶Œìƒì¥ì˜ˆì •ì¼",
        "ìƒì¥ì˜ˆì •ì¼",
    ])

    return fields

# =========================
# Money parsing / Raise amount (heuristic)
# =========================
def parse_int_kr(s: str) -> int:
    if not s:
        return 0
    s = re.sub(r"[^\d,]", "", s)
    if not s:
        return 0
    try:
        return int(s.replace(",", ""))
    except Exception:
        return 0

def fmt_won(n: int) -> str:
    if n <= 0:
        return "N/A"
    return f"{n:,}ì›"

def extract_raise_amount_krw(doc_text: str) -> int:
    """
    ì¡°ë‹¬ê¸ˆì•¡(ì¶”ì •):
    - 'ëª¨ì§‘', 'ë§¤ì¶œ', 'ê¸ˆì•¡' ê·¼ì²˜ì˜ 'xxxì›' ìš°ì„ 
    - ì—†ìœ¼ë©´ ë¬¸ì„œ ë‚´ ê°€ì¥ í° 'ì›' ê¸ˆì•¡(ìƒì‹ì  ìƒí•œ ì ìš©)
    """
    if not doc_text:
        return 0

    lines = [ln.strip() for ln in doc_text.splitlines() if ln.strip()]
    amt_pat = re.compile(r"(\d{1,3}(?:,\d{3})+|\d+)\s*ì›")
    focus_kw = re.compile(r"(ëª¨ì§‘|ë§¤ì¶œ|ë°œí–‰|ì¡°ë‹¬|ìê¸ˆ|ì´ì•¡|ê¸ˆì•¡)", re.I)

    candidates = []
    for ln in lines:
        if not focus_kw.search(ln):
            continue
        for m in amt_pat.finditer(ln):
            v = parse_int_kr(m.group(1))
            if v > 0:
                candidates.append(v)

    # 1) í‚¤ì›Œë“œ ë¼ì¸ í›„ë³´ê°€ ìˆìœ¼ë©´ ê·¸ì¤‘ ìµœëŒ€ë¥¼ ì‚¬ìš©
    if candidates:
        v = max(candidates)
        # ë¹„ì •ìƒ ì´ˆëŒ€í˜• ë°©ì§€(100ì¡° ì´ìƒì€ ë³´í†µ ì˜¤íƒ) - í•„ìš”ì‹œ ì¡°ì •
        if v >= 100_000_000_000_000:
            return 0
        return v

    # 2) fallback: ë¬¸ì„œ ì „ì²´ì—ì„œ í•©ë¦¬ì  ë²”ìœ„ ë‚´ ìµœëŒ€ 'ì›' ê¸ˆì•¡
    all_vals = []
    for ln in lines:
        for m in amt_pat.finditer(ln):
            v = parse_int_kr(m.group(1))
            if v > 0:
                all_vals.append(v)
    if not all_vals:
        return 0

    v = max(all_vals)
    if v >= 100_000_000_000_000:
        return 0
    return v

# =========================
# Naver finance: current price + market cap
# =========================
def fetch_naver_html(stock_code: str) -> str:
    url = NAVER_ITEM.format(stock_code)
    last = None
    for _ in range(max(1, NAVER_RETRY)):
        try:
            r = S.get(url, timeout=NAVER_TIMEOUT)
            r.raise_for_status()
            return r.text
        except Exception as e:
            last = e
    raise RuntimeError(f"Naver fetch failed: {last}")

def extract_current_price_from_naver(ht: str) -> int:
    # í˜„ì¬ê°€ ì˜ì—­(ì—¬ëŸ¬ íŒ¨í„´ ëŒ€ì‘)
    # ì˜ˆ) <p class="no_today"><span class="blind">12,340</span>
    m = re.search(r'no_today[^>]*>\s*<[^>]*>\s*<span[^>]*class="blind"[^>]*>([\d,]+)</span>', ht, re.I | re.S)
    if m:
        return parse_int_kr(m.group(1))

    # fallback: "í˜„ì¬ê°€" í…ìŠ¤íŠ¸ ê·¼ì²˜
    m = re.search(r"(í˜„ì¬ê°€|ì¢…ê°€)[^0-9]{0,30}([\d,]+)", ht)
    if m:
        return parse_int_kr(m.group(2))
    return 0

def extract_market_cap_from_naver(ht: str) -> int:
    """
    ë„¤ì´ë²„ëŠ” ì‹œê°€ì´ì•¡ì„ 'ì‹œê°€ì´ì•¡' ë¼ë²¨ ê·¼ì²˜ì— ìˆ«ìë¡œ ë…¸ì¶œ.
    ë‹¨ìœ„ê°€ 'ì–µì›'ë¡œ ë³´ì´ëŠ” ê²½ìš°ê°€ ìˆì–´ ë³€í™˜ ì²˜ë¦¬.
    """
    # 1) "ì‹œê°€ì´ì•¡" ê·¼ì²˜ì—ì„œ ìˆ«ì+ë‹¨ìœ„(ì–µì›/ì¡°/ì› ë“±) íƒì§€
    # ì˜ˆ: ì‹œê°€ì´ì•¡ 1ì¡° 2,345ì–µ / ë˜ëŠ” 12,345ì–µì›
    m = re.search(r"ì‹œê°€ì´ì•¡\s*</th>\s*<td[^>]*>\s*([^<]+)</td>", ht, re.I | re.S)
    if m:
        raw = html.unescape(m.group(1))
        raw = re.sub(r"\s+", " ", raw).strip()

        # í˜•íƒœ: "12ì¡° 3,456ì–µ" ì²˜ë¦¬
        tj = re.search(r"(\d{1,3}(?:,\d{3})+|\d+)\s*ì¡°", raw)
        ek = re.search(r"(\d{1,3}(?:,\d{3})+|\d+)\s*ì–µ", raw)
        if tj or ek:
            val = 0
            if tj:
                val += parse_int_kr(tj.group(1)) * 1_0000_0000_0000  # 1ì¡° = 1e12
            if ek:
                val += parse_int_kr(ek.group(1)) * 100_000_000        # 1ì–µ = 1e8
            return val if val > 0 else 0

        # í˜•íƒœ: "12,345ì–µì›" ì²˜ë¦¬
        m2 = re.search(r"([\d,]+)\s*ì–µ", raw)
        if m2:
            return parse_int_kr(m2.group(1)) * 100_000_000

        # í˜•íƒœ: "123,456,789,000ì›" ì²˜ë¦¬
        m3 = re.search(r"([\d,]+)\s*ì›", raw)
        if m3:
            return parse_int_kr(m3.group(1))

    # 2) fallback: ë³¸ë¬¸ì—ì„œ 'ì‹œê°€ì´ì•¡' ë‹¤ìŒ ìˆ«ì/ë‹¨ìœ„ íƒì§€
    m = re.search(r"ì‹œê°€ì´ì•¡[^0-9]{0,80}([\d,]+)\s*ì–µ", ht)
    if m:
        return parse_int_kr(m.group(1)) * 100_000_000

    return 0

def get_price_and_mcap(stock_code: str) -> tuple[int, int]:
    if not stock_code or not re.fullmatch(r"\d{6}", stock_code):
        return 0, 0
    ht = fetch_naver_html(stock_code)
    px = extract_current_price_from_naver(ht)
    mc = extract_market_cap_from_naver(ht)
    return px, mc

# =========================
# ìµœëŒ€ì£¼ì£¼ ì°¸ì—¬ ì—¬ë¶€(íœ´ë¦¬ìŠ¤í‹±)
# =========================
def extract_major_shareholder_participation(doc_text: str) -> tuple[str, str]:
    """
    ì°¸ì—¬/ë¶ˆì°¸/ë¯¸í™•ì¸ + ê·¼ê±° ë¬¸êµ¬ ì¼ë¶€ ë°˜í™˜
    """
    if not doc_text:
        return "ë¯¸í™•ì¸", ""

    lines = [ln.strip() for ln in doc_text.splitlines() if ln.strip()]
    # ìµœëŒ€ì£¼ì£¼/íŠ¹ìˆ˜ê´€ê³„ì¸/ìµœëŒ€ì£¼ì£¼ì˜ ì²­ì•½/ì°¸ì—¬/ì¸ìˆ˜ ë“±
    pat = re.compile(r"(ìµœëŒ€\s*ì£¼ì£¼|ìµœëŒ€ì£¼ì£¼|íŠ¹ìˆ˜ê´€ê³„ì¸|ëŒ€ì£¼ì£¼).{0,60}(ì°¸ì—¬|ì²­ì•½|ì¸ìˆ˜|ë¶ˆì°¸|ë¯¸ì°¸ì—¬|í¬ê¸°)", re.I)
    neg = re.compile(r"(ë¶ˆì°¸|ë¯¸ì°¸ì—¬|í¬ê¸°)", re.I)
    pos = re.compile(r"(ì°¸ì—¬|ì²­ì•½|ì¸ìˆ˜)", re.I)

    for ln in lines:
        if "ìµœëŒ€" not in ln and "ëŒ€ì£¼ì£¼" not in ln and "íŠ¹ìˆ˜" not in ln:
            continue
        m = pat.search(ln)
        if not m:
            continue
        snippet = _norm_ws(ln)[:180]
        if neg.search(ln):
            return "ë¶ˆì°¸", snippet
        if pos.search(ln):
            return "ì°¸ì—¬", snippet

    # fallback: 'ìµœëŒ€ì£¼ì£¼' ë¬¸ë§¥ 1~2ì¤„ í•©ì³ì„œ íŒë‹¨
    for i, ln in enumerate(lines):
        if re.search(r"(ìµœëŒ€\s*ì£¼ì£¼|ìµœëŒ€ì£¼ì£¼|ëŒ€ì£¼ì£¼|íŠ¹ìˆ˜ê´€ê³„ì¸)", ln):
            ctx = ln
            if i + 1 < len(lines):
                ctx2 = _norm_ws(lines[i + 1])
                if ctx2:
                    ctx = _norm_ws(ctx + " " + ctx2)
            if neg.search(ctx):
                return "ë¶ˆì°¸", ctx[:180]
            if pos.search(ctx):
                return "ì°¸ì—¬", ctx[:180]

    return "ë¯¸í™•ì¸", ""

# =========================
# N/A ìˆ¨ê¹€ + ì¹´ë“œ ë Œë”ë§ + ìœ„í—˜ë„
# =========================
def _is_empty_value(v: str) -> bool:
    if v is None:
        return True
    s = str(v).strip()
    if not s:
        return True
    if s.upper() == "N/A":
        return True
    if s in ("0", "0ì›", "0 ì£¼", "0ì£¼"):
        return True
    return False

def add_if(lines: list[str], label: str, value: str):
    if _is_empty_value(value):
        return
    lines.append(f"â€¢ <b>{html.escape(label)}</b>: {html.escape(value)}")

def fmt_pct(x: float) -> str:
    return f"{x:.2f}%"

def risk_score(ev_type: str, alloc: str, market: str, doc_text: str, fields: dict,
               raise_krw: int, mcap_krw: int, discount_pct: float | None,
               major_part: str) -> tuple[int, str, str]:
    """
    0~100 íœ´ë¦¬ìŠ¤í‹±(ì—…ê·¸ë ˆì´ë“œ):
    - ê¸°ì¡´(ìœ í˜•/ì‹œì¥/ëª©ì /ì¼ì •) + ì‹œì´ëŒ€ë¹„ ë¹„ìœ¨ + í• ì¸ìœ¨ + ìµœëŒ€ì£¼ì£¼ ë¶ˆì°¸ ê°€ì¤‘
    """
    score = 10

    et = (ev_type or "").strip()
    if et == "ìœ ìƒ":
        score += 38
    elif et == "ìœ ë¬´ìƒ":
        score += 28
    elif et == "ë¬´ìƒ":
        score += 8
    else:
        score += 15

    mk = (market or "").upper()
    if mk == "KOSDAQ":
        score += 10
    elif mk == "KONEX":
        score += 15
    elif mk == "KOSPI":
        score += 5
    else:
        score += 7

    if alloc == "ì£¼ì£¼ë°°ì •":
        score += 8
    elif alloc == "ì¼ë°˜ì£¼ì£¼ë°°ì •":
        score += 6

    purpose = (fields.get("ìê¸ˆì¡°ë‹¬ì˜ëª©ì ") or "")
    if re.search(r"(ì±„ë¬´|ìƒí™˜|ì°¨ì…|ëŒ€ì¶œ)", purpose):
        score += 18
    if re.search(r"(ìš´ì˜|ìš´ì „ìê¸ˆ)", purpose):
        score += 10
    if re.search(r"(íƒ€ë²•ì¸|M&A|ì¸ìˆ˜|ì·¨ë“|íˆ¬ì)", purpose):
        score += 12

    for k in ["ì²­ì•½ì¼", "ì˜ˆì •ê°€", "í™•ì •ì¼", "ì‹ ì£¼ì¸ìˆ˜ê¶Œìƒì¥ì˜ˆì •ê¸°ê°„", "ì‹ ì£¼ì˜ìƒì¥ì˜ˆì •ì¼"]:
        if not _is_empty_value(fields.get(k, "N/A")):
            score += 4

    # âœ… ì‹œì´ ëŒ€ë¹„ ì¡°ë‹¬ê¸ˆì•¡ ë¹„ìœ¨ ë°˜ì˜
    if raise_krw > 0 and mcap_krw > 0:
        ratio = raise_krw / mcap_krw  # 0~1+
        if ratio >= 0.50:
            score += 22
        elif ratio >= 0.30:
            score += 16
        elif ratio >= 0.15:
            score += 10
        elif ratio >= 0.05:
            score += 6
        else:
            score += 2

    # âœ… í• ì¸ìœ¨ ë°˜ì˜(ì˜ˆì •ê°€ê°€ í˜„ì¬ê°€ ëŒ€ë¹„ í¬ê²Œ ë‚®ìœ¼ë©´ ì´ë²¤íŠ¸ ì˜í–¥â†‘)
    if discount_pct is not None:
        if discount_pct >= 35:
            score += 16
        elif discount_pct >= 25:
            score += 12
        elif discount_pct >= 15:
            score += 8
        elif discount_pct >= 8:
            score += 4

    # âœ… ìµœëŒ€ì£¼ì£¼ ì°¸ì—¬(ë¶ˆì°¸ì´ë©´ ê°€ì¤‘)
    if major_part == "ë¶ˆì°¸":
        score += 18
    elif major_part == "ì°¸ì—¬":
        score -= 6  # ì°¸ì—¬ëŠ” ë¦¬ìŠ¤í¬ ì™„í™” ì‹ í˜¸ë¡œ ì•½í•˜ê²Œ ê°ì 

    # clamp
    score = max(0, min(100, score))

    if score >= 80:
        emoji, grade = "ğŸ”´", "ë†’ìŒ"
    elif score >= 60:
        emoji, grade = "ğŸŸ ", "ì¤‘ê°„"
    elif score >= 40:
        emoji, grade = "ğŸŸ¡", "ë‚®ìŒ"
    else:
        emoji, grade = "ğŸŸ¢", "ë§¤ìš°ë‚®ìŒ"
    return score, grade, emoji

def build_card(corp: str, market: str, ev_type: str, alloc: str, rcept_dt: str, rpt_nm: str, url: str,
               doc_text: str, fields: dict, stock_code: str | None,
               cur_px: int, mcap_krw: int, raise_krw: int,
               ratio_pct: float | None, discount_pct: float | None,
               major_part: str, major_snip: str) -> str:

    score, grade, emoji = risk_score(
        ev_type, alloc, market, doc_text, fields,
        raise_krw=raise_krw, mcap_krw=mcap_krw, discount_pct=discount_pct,
        major_part=major_part
    )

    lines = []
    lines.append(f"{emoji} <b>ì¦ì ê³µì‹œ ê°ì§€</b>  <i>(ìœ„í—˜ë„ {score}/100 Â· {grade})</i>")
    lines.append(f"ğŸ¢ <b>{html.escape(corp)}</b>  <i>({html.escape(market)})</i>")
    lines.append(f"ğŸ§¾ ìœ í˜•: <b>{html.escape(ev_type)}</b> / ë°°ì •: <b>{html.escape(alloc)}</b>")
    if rcept_dt:
        lines.append(f"ğŸ“… ì ‘ìˆ˜ì¼: {html.escape(rcept_dt)}")
    if stock_code and re.fullmatch(r"\d{6}", stock_code):
        lines.append(f"ğŸ” ì¢…ëª©ì½”ë“œ: {html.escape(stock_code)}")

    lines.append("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    lines.append(f"ğŸ“Œ <b>ê³µì‹œëª…</b>")
    lines.append(f"{html.escape(rpt_nm)}")
    lines.append("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")

    # ğŸ§  í•µì‹¬
    core = []
    add_if(core, "ìê¸ˆì¡°ë‹¬ì˜ëª©ì ", fields.get("ìê¸ˆì¡°ë‹¬ì˜ëª©ì ", "N/A"))
    add_if(core, "ì‹ ì£¼ë°°ì •ê¸°ì¤€ì¼", fields.get("ì‹ ì£¼ë°°ì •ê¸°ì¤€ì¼", "N/A"))
    if core:
        lines.append("ğŸ§  <b>í•µì‹¬</b>")
        lines.extend(core)
        lines.append("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")

    # ğŸ’° ê°€ê²©
    price = []
    add_if(price, "ì˜ˆì •ê°€", fields.get("ì˜ˆì •ê°€", "N/A"))
    add_if(price, "í™•ì •ì¼", fields.get("í™•ì •ì¼", "N/A"))
    if price:
        lines.append("ğŸ’° <b>ê°€ê²©</b>")
        lines.extend(price)
        lines.append("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")

    # ğŸ—“ï¸ ì¼ì •
    sched = []
    add_if(sched, "ì‹ ì£¼ì¸ìˆ˜ê¶Œìƒì¥ì˜ˆì •ê¸°ê°„", fields.get("ì‹ ì£¼ì¸ìˆ˜ê¶Œìƒì¥ì˜ˆì •ê¸°ê°„", "N/A"))
    add_if(sched, "ì²­ì•½ì¼", fields.get("ì²­ì•½ì¼", "N/A"))
    add_if(sched, "ì‹ ì£¼ì˜ìƒì¥ì˜ˆì •ì¼", fields.get("ì‹ ì£¼ì˜ìƒì¥ì˜ˆì •ì¼", "N/A"))
    if sched:
        lines.append("ğŸ—“ï¸ <b>ì¼ì •</b>")
        lines.extend(sched)
        lines.append("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")

    # ğŸ“Š ê·œëª¨/ë¹„ìœ¨/í• ì¸
    size = []
    if raise_krw > 0:
        add_if(size, "ì¡°ë‹¬ê¸ˆì•¡(ì¶”ì •)", fmt_won(raise_krw))
    if mcap_krw > 0:
        add_if(size, "ì‹œê°€ì´ì•¡(ì¶”ì •)", fmt_won(mcap_krw))
    if ratio_pct is not None:
        add_if(size, "ì‹œì´ ëŒ€ë¹„ ì¡°ë‹¬ë¹„ìœ¨", fmt_pct(ratio_pct))
    if cur_px > 0:
        add_if(size, "í˜„ì¬ê°€(ì¶”ì •)", f"{cur_px:,}ì›")
    if discount_pct is not None:
        add_if(size, "ì˜ˆì •ê°€ í• ì¸ìœ¨", fmt_pct(discount_pct))
    if major_part != "ë¯¸í™•ì¸":
        add_if(size, "ìµœëŒ€ì£¼ì£¼ ì°¸ì—¬", major_part)
        if major_snip:
            add_if(size, "ê·¼ê±°", major_snip)

    if size:
        lines.append("ğŸ“Š <b>ê·œëª¨/ë¦¬ìŠ¤í¬ ë³´ê°•</b>")
        lines.extend(size)
        lines.append("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")

    lines.append("â¡ï¸ ì•„ë˜ ë²„íŠ¼ìœ¼ë¡œ ì›ë¬¸ í™•ì¸")
    return "\n".join(lines)

# =========================
# helpers: ì˜ˆì •ê°€ ìˆ«ì ì¶”ì¶œ
# =========================
def extract_issue_price_from_field(v: str) -> int:
    # "12,345ì›" "12,345" ê°™ì€ í˜•íƒœì—ì„œ ìˆ«ìë§Œ
    if not v or v.strip().upper() == "N/A":
        return 0
    m = re.search(r"([\d,]+)\s*ì›?", v)
    if not m:
        return 0
    return parse_int_kr(m.group(1))

# =========================
# main
# =========================
def main():
    st = load_state()
    sent = 0

    items = fetch_list_pages()

    for it in items:
        rno = (it.get("rcept_no") or "").strip()
        if not rno:
            continue
        if is_seen(st, rno):
            continue

        corp_cls = (it.get("corp_cls") or "").strip().upper()
        if not market_ok(corp_cls):
            mark_seen(st, rno)
            continue

        rpt_nm = (it.get("report_nm") or "").strip()
        if not INC_REPORT.search(rpt_nm):
            mark_seen(st, rno)
            continue

        # ì›ë¬¸ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
        try:
            doc_text = fetch_document_text(rno)
        except Exception:
            mark_seen(st, rno)
            continue

        # ì œ3ìë°°ì • í¬í•¨ì´ë©´ ì œì™¸
        if EXC_3RD.search(doc_text):
            mark_seen(st, rno)
            continue

        alloc = classify_allocation(doc_text)
        if alloc == "N/A":
            mark_seen(st, rno)
            continue

        fields = extract_fields(doc_text)
        ev_type = classify_event_type(rpt_nm)

        corp = (it.get("corp_name") or "N/A").strip()
        rcept_dt = (it.get("rcept_dt") or "").strip()
        url = VIEW_URL.format(rno)
        market_name = {"Y": "KOSPI", "K": "KOSDAQ", "N": "KONEX", "E": "OTHER"}.get(corp_cls, corp_cls or "N/A")

        # âœ… ì¡°ë‹¬ê¸ˆì•¡(ì¶”ì •)
        raise_krw = extract_raise_amount_krw(doc_text)

        # âœ… ì¢…ëª©ì½”ë“œ(ìˆìœ¼ë©´ ì‹œì´/í˜„ì¬ê°€/í• ì¸ìœ¨ ê³„ì‚°)
        stock_code = (it.get("stock_code") or "").strip()
        if not re.fullmatch(r"\d{6}", stock_code):
            stock_code = ""

        cur_px, mcap_krw = (0, 0)
        if stock_code:
            try:
                cur_px, mcap_krw = get_price_and_mcap(stock_code)
            except Exception:
                cur_px, mcap_krw = (0, 0)

        # âœ… ì‹œì´ ëŒ€ë¹„ ë¹„ìœ¨(%)
        ratio_pct = None
        if raise_krw > 0 and mcap_krw > 0:
            ratio_pct = (raise_krw / mcap_krw) * 100.0

        # âœ… í• ì¸ìœ¨(%): ì˜ˆì •ê°€ vs í˜„ì¬ê°€
        discount_pct = None
        issue_px = extract_issue_price_from_field(fields.get("ì˜ˆì •ê°€", "N/A"))
        if issue_px > 0 and cur_px > 0:
            discount_pct = (1.0 - (issue_px / cur_px)) * 100.0

        # âœ… ìµœëŒ€ì£¼ì£¼ ì°¸ì—¬ ì—¬ë¶€
        major_part, major_snip = extract_major_shareholder_participation(doc_text)

        msg = build_card(
            corp=corp,
            market=market_name,
            ev_type=ev_type,
            alloc=alloc,
            rcept_dt=rcept_dt,
            rpt_nm=rpt_nm,
            url=url,
            doc_text=doc_text,
            fields=fields,
            stock_code=stock_code or None,
            cur_px=cur_px,
            mcap_krw=mcap_krw,
            raise_krw=raise_krw,
            ratio_pct=ratio_pct,
            discount_pct=discount_pct,
            major_part=major_part,
            major_snip=major_snip,
        )

        tg_send_safe(msg, button_url=url)

        mark_seen(st, rno)
        sent += 1

    save_state(st)
    print(f"OK sent={sent} seen={len(st.get('seen', []))}")

if __name__ == "__main__":
    main()
